{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:133: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "import docxpy as dx\n",
    "from tkinter import scrolledtext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ps=PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    new_text=re.sub(f'[{string.punctuation}]','',text)\n",
    "    words=word_tokenize(new_text)\n",
    "    new_words=[]\n",
    "    sw=stopwords.words('english')\n",
    "    sw.remove('not')\n",
    "    for w in words:\n",
    "        if(w not in sw):\n",
    "            nw=ps.stem(w)\n",
    "            new_words.append(nw)\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "root=Tk()\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "def review_analysis():\n",
    "    def review():\n",
    "        df=pd.read_csv('C:/Users/HP/Downloads/dataset/dataset/sentiment/Restaurant_Reviews.txt',delimiter='\\t')\n",
    "        new_reviews=list(map(clean_text,df.Review))\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        tv=TfidfVectorizer(ngram_range=(1,2))\n",
    "        X=tv.fit_transform(new_reviews).toarray()\n",
    "        y=df.Liked\n",
    "        test_sample=entry_review.get()\n",
    "        X_test=tv.transform([clean_text(test_sample)]).toarray()\n",
    "        mnb=MultinomialNB()\n",
    "        mnb.fit(X,y)\n",
    "        result_comment=mnb.predict(X_test)\n",
    "        if(result_comment==1):\n",
    "            lbl_result.config(text=\"Positive\",bg='teal',fg='white')\n",
    "        else:\n",
    "            lbl_result.config(text=\"Negative\",bg='teal',fg='white')\n",
    "\n",
    "    new_window=Toplevel(root)\n",
    "    lbl_title=Label(new_window,text='Restaurant Analysis',font=('cambria',24,'bold','underline'),bg='teal',fg='white')\n",
    "    lbl_title.pack(padx=10)\n",
    "\n",
    "    lbl=Label(new_window,text=\"Enter Review: \",font=('cambria',14,'bold'),bg='teal',fg='white')\n",
    "    lbl.place(x=500,y=150)\n",
    "\n",
    "    entry_review=Entry(new_window,font=('',14),bd=3)\n",
    "    entry_review.place(x=800,y=150)\n",
    "\n",
    "    btn_1=Button(new_window,text=\"Get Sentiment\", command=review, font=('book antiqua',13),bd=5)\n",
    "    btn_1.place(x=700,y=250)\n",
    "    \n",
    "    lbl_result=Label(new_window,font=('cambria',24,'bold'))\n",
    "    lbl_result.place(x=700,y=450)\n",
    "    \n",
    "\n",
    "def spam_detection():\n",
    "    def spam():\n",
    "        df=pd.read_csv('C:/Users/HP/Downloads/dataset/dataset/sentiment/spam_ham.txt',delimiter='\\t',header=None)\n",
    "        df.columns=['msg_type','msg']\n",
    "        new_reviews=list(map(clean_text,df.msg))\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        tv=TfidfVectorizer(ngram_range=(1,2))\n",
    "        X=tv.fit_transform(new_reviews).toarray()\n",
    "        y=df.msg_type\n",
    "        test_sample=entry_review.get()\n",
    "        X_test=tv.transform([clean_text(test_sample)]).toarray()\n",
    "        mnb=MultinomialNB()\n",
    "        mnb.fit(X,y)\n",
    "        result_comment=mnb.predict(X_test)\n",
    "        if(result_comment==\"ham\"):\n",
    "            lbl_result.config(text=\"Ham Message\",bg='teal',fg='white')\n",
    "        else:\n",
    "            lbl_result.config(text=\"Spam Message\",bg='teal',fg='white')\n",
    "            \n",
    "    new_window=Toplevel(root)\n",
    "    lbl_title=Label(new_window,text='Spam Detection',font=('cambria',24,'bold','underline'),bg='teal',fg='white')\n",
    "    lbl_title.pack(padx=10)\n",
    "\n",
    "    lbl=Label(new_window,text=\"Enter Message: \",font=('cambria',14,'bold'),bg='teal',fg='white')\n",
    "    lbl.place(x=500,y=150)\n",
    "\n",
    "    entry_review=Entry(new_window,font=('',14),bd=3)\n",
    "    entry_review.place(x=800,y=150)\n",
    "\n",
    "    btn_1=Button(new_window,text=\"Detect message type\", command=spam, font=('book antiqua',13),bd=5)\n",
    "    btn_1.place(x=700,y=250)\n",
    "    \n",
    "    lbl_result=Label(new_window,font=('cambria',24,'bold'))\n",
    "    lbl_result.place(x=700,y=450)\n",
    "    \n",
    "def tweet_analysis():\n",
    "    def tweet():\n",
    "        df=pd.read_csv('C:/Users/HP/Downloads/dataset/dataset/sentiment/twitter.csv', header=None, encoding='latin-1')\n",
    "        df.columns=['no.','target','review']\n",
    "        \n",
    "        X=df.review.iloc[:3000]\n",
    "        y=df.target.iloc[:3000]\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=10,test_size=.2)\n",
    "        new_reviews=list(map(clean_text,X_train))\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        tv=TfidfVectorizer(ngram_range=(1,2))\n",
    "        X_feature=tv.fit_transform(new_reviews).toarray()\n",
    "        y_feature=y_train\n",
    "        test_sample=entry_review.get()\n",
    "        X_test_sample=tv.transform([clean_text(test_sample)]).toarray()\n",
    "       \n",
    "        gb=GaussianNB()\n",
    "    \n",
    "        gb.fit(X_feature,y_feature)\n",
    "        result_comment=gb.predict(X_test_sample)\n",
    "        if(result_comment==1):\n",
    "            lbl_result.config(text=\"Positive\",bg='teal',fg='white')\n",
    "        else:\n",
    "            lbl_result.config(text=\"Negative\",bg='teal',fg='white')\n",
    "    new_window=Toplevel(root)\n",
    "    lbl_title=Label(new_window,text='Tweet Analysis',font=('cambria',24,'bold','underline'),bg='teal',fg='white')\n",
    "    lbl_title.pack(padx=10)\n",
    "\n",
    "    lbl=Label(new_window,text=\"Enter Tweet: \",font=('cambria',14,'bold'),bg='teal',fg='white')\n",
    "    lbl.place(x=500,y=150)\n",
    "\n",
    "    entry_review=Entry(new_window,font=('',14),bd=3)\n",
    "    entry_review.place(x=800,y=150)\n",
    "\n",
    "    btn_1=Button(new_window,text=\"Get Sentiment\", command=tweet, font=('book antiqua',13),bd=5)\n",
    "    btn_1.place(x=700,y=250)\n",
    "    \n",
    "    lbl_result=Label(new_window,font=('cambria',24,'bold'))\n",
    "    lbl_result.place(x=700,y=450)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "root.state('zoomed')\n",
    "root.configure(bg='teal')\n",
    "root.resizable(width=False,height=False)\n",
    "root.title(\"Sentiment Analysis\")\n",
    "\n",
    "lbl_title=Label(root,text='Sentiment Analysis',font=('cambria',24,'bold','underline'),bg='teal',fg='white')\n",
    "lbl_title.pack(padx=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "btn_1=Button(root,text=\"Review Analysis\", command=review_analysis,font=('book antiqua',13),bd=5)\n",
    "btn_1.place(x=700,y=150)\n",
    "\n",
    "btn_2=Button(root,text=\" Spam Detection \",command=spam_detection, font=('book antiqua',13),bd=5)\n",
    "btn_2.place(x=700,y=250)\n",
    "\n",
    "btn_3=Button(root,text=\" Tweet Analysis \",command=tweet_analysis, font=('book antiqua',13),bd=5)\n",
    "btn_3.place(x=700,y=350)\n",
    "\n",
    "\n",
    "text_box=scrolledtext.ScrolledText(root,width=35,height=20,font=('',10))\n",
    "\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
